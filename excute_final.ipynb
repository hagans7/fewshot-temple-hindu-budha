{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omniglot Character Set Classification Using Prototypical Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we will see how to use prototypical networks to perform the classification task. We use omniglot dataset for performing classification. Omniglot dataset comprises of 1,623 handwritten characters from 50 different alphabets and each character has 20 different examples written by different people. Since we want our network to learn from little data, we train them in the same way. We sample five examples from each class and use that as our support set. We learn the embeddings of our support set using a sequence of four convolution blocks as our encoder and build the class prototype. Similarly, we sample five examples from each class for query set, learn the query set embeddings and predict the query set class by comparing the Euclidean distance between the query set embeddings and class prototype. Let us better understand this by going through it step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import all the required libraries,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we convert this image into an array? we can use np.array function to convert these images into an array and then we reshape it to 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_name = 'candi/train/budha/candi_banyunibo_yogyakarta_budha/image4.PNG'\n",
    "alphabet, character, rotation = 'budha/candi_banyunibo_yogyakarta_budha/rot000'.split('/')\n",
    "rotation = float(rotation[3:])\n",
    "\n",
    "# image_name = 'candi/data\\\\budha/candi_banyunibo_yogyakarta_budha\\\\image4.PNG'\n",
    "# alphabet, rotation = 'budha/candi_jago_malang_budha/rot000'.split('/')\n",
    "# candi/train/budha\\candi_banyunibo_yogyakarta_budha\n",
    "# rotation = float(rotation[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126., 126., 122., 121., 120., 121., 122., 126., 125., 132., 121.,\n",
       "        121., 121., 121., 121., 120., 119., 119., 119., 119., 120., 121.,\n",
       "        119., 119., 119., 116., 113., 120.],\n",
       "       [119., 121., 120., 121., 121., 121., 123., 124., 122., 119., 120.,\n",
       "        121., 121., 121., 121., 121., 120., 120., 120., 120., 121., 121.,\n",
       "        118., 119., 119., 120., 120., 128.],\n",
       "       [119., 116., 121., 122., 120., 121., 122., 121., 121., 120., 122.,\n",
       "        122., 122., 122., 121., 122., 123., 121., 122., 122., 118., 117.,\n",
       "        120., 121., 122., 127., 125., 146.],\n",
       "       [150., 130., 113., 120., 120., 121., 122., 121., 121., 120., 122.,\n",
       "        122., 124., 124., 122., 123., 125., 125., 126., 125., 129., 133.,\n",
       "        132., 119., 110., 109., 148., 154.],\n",
       "       [171., 189., 121., 117., 121., 120., 121., 122., 123., 122., 123.,\n",
       "        123., 127., 128., 124., 125., 127., 125., 121., 123., 134., 136.,\n",
       "        142., 121., 129., 153., 158., 147.],\n",
       "       [136., 173., 158., 118., 121., 121., 121., 123., 125., 124., 125.,\n",
       "        126., 128., 132., 132., 117., 135., 127., 125., 123., 125., 128.,\n",
       "        132., 142., 151., 146., 137., 153.],\n",
       "       [125., 133., 136., 123., 123., 122., 122., 122., 125., 125., 127.,\n",
       "        129., 135., 140., 129.,  72., 135., 139., 131., 128., 131., 126.,\n",
       "        125., 136., 124., 122., 127., 127.],\n",
       "       [126., 122., 121., 123., 124., 124., 124., 125., 128., 128., 134.,\n",
       "        141., 145., 149.,  98.,  59., 103., 150., 145., 142., 133., 129.,\n",
       "        127., 123., 119., 119., 119., 118.],\n",
       "       [122., 128., 130., 125., 126., 126., 126., 128., 133., 140., 147.,\n",
       "        137., 108.,  97.,  87.,  70.,  70.,  89., 124., 133., 146., 141.,\n",
       "        133., 128., 127., 127., 122., 123.],\n",
       "       [128., 131., 134., 131., 132., 129., 127., 134., 147., 154., 113.,\n",
       "         79.,  98., 110., 120., 104.,  92.,  94.,  93.,  89., 111., 151.,\n",
       "        149., 138., 129., 126., 124., 122.],\n",
       "       [134., 138., 142., 144., 143., 138., 138., 135., 124.,  94.,  88.,\n",
       "         87.,  88.,  97., 103., 108.,  98.,  89.,  87.,  80.,  76.,  77.,\n",
       "        100., 124., 139., 135., 133., 132.],\n",
       "       [138., 139., 103., 107., 137., 155., 155., 124.,  39.,  48.,  51.,\n",
       "         45.,  58.,  71.,  58.,  73.,  62.,  67.,  53.,  51.,  47.,  48.,\n",
       "         44., 128., 161., 165., 162., 157.],\n",
       "       [161., 123.,  94.,  89., 110., 126., 136., 164.,  72.,  59.,  66.,\n",
       "         79.,  82.,  84.,  98.,  95., 106.,  87.,  81.,  84.,  79.,  60.,\n",
       "         63., 167., 162., 147., 133., 120.],\n",
       "       [179., 128., 111., 125., 132., 112., 110., 141., 114.,  99.,  94.,\n",
       "         97.,  95.,  73.,  96.,  92.,  96.,  77.,  79., 108., 100., 113.,\n",
       "         83., 147., 126.,  97.,  90.,  93.],\n",
       "       [132., 116., 119., 130., 158., 135., 116., 124., 110., 114., 107.,\n",
       "         57.,  60.,  68.,  85.,  81.,  92.,  73.,  43.,  71., 105., 116.,\n",
       "         94., 125., 128., 125., 127., 103.],\n",
       "       [111., 100., 109., 122., 116., 101.,  95., 127.,  93.,  88., 123.,\n",
       "         81.,  78., 108.,  94.,  17.,  84., 100.,  54.,  71., 110.,  98.,\n",
       "         96., 113., 127., 113., 122.,  89.],\n",
       "       [ 94.,  87.,  88.,  89.,  96., 106., 116., 100., 101.,  99., 125.,\n",
       "         49.,  61., 133.,  93.,  12.,  94., 102.,  29.,  44., 130., 122.,\n",
       "        123., 114., 128., 126., 122.,  96.],\n",
       "       [ 88.,  76., 105., 113., 108., 112.,  90.,  77.,  99., 107.,  90.,\n",
       "         55.,  45., 105.,  78.,   8.,  75., 109.,  55.,  60.,  90., 110.,\n",
       "        111., 121., 123., 120., 121., 117.],\n",
       "       [ 92.,  68., 103.,  94.,  90.,  74.,  66., 112., 131., 127., 119.,\n",
       "        100.,  86., 112.,  93.,  44.,  81., 103., 106., 110., 110., 116.,\n",
       "        117., 109.,  79.,  93., 107., 118.],\n",
       "       [ 94.,  86.,  89.,  60.,  81., 101.,  91.,  82.,  89.,  88.,  83.,\n",
       "        105., 101., 118., 124., 120., 116., 120.,  85., 100.,  87.,  75.,\n",
       "         83.,  89.,  82.,  81.,  83.,  94.],\n",
       "       [116., 117., 106.,  82.,  98.,  74.,  50.,  45.,  47.,  27.,  41.,\n",
       "         65.,  49., 100., 107., 104., 101., 110.,  59.,  72.,  66.,  27.,\n",
       "         49.,  56.,  85.,  79.,  77.,  65.],\n",
       "       [ 46.,  48.,  68.,  72.,  92.,  97.,  82.,  70.,  69.,  72.,  87.,\n",
       "         85.,  80., 100.,  88., 100., 100., 103., 102., 101., 111.,  63.,\n",
       "         64.,  65.,  73.,  80.,  86.,  90.],\n",
       "       [ 94., 111., 130., 115.,  77.,  69.,  69.,  70.,  71.,  74.,  57.,\n",
       "         52.,  60.,  47., 102., 102.,  86.,  73.,  53.,  62.,  75.,  69.,\n",
       "         65.,  55.,  50.,  61.,  93.,  79.],\n",
       "       [147., 146., 141., 139., 141., 139., 143., 143., 144., 133., 135.,\n",
       "        149., 135., 106., 121., 115., 113., 103., 102., 135., 142., 133.,\n",
       "        120., 127., 126., 120., 121., 125.],\n",
       "       [136., 136., 136., 140., 143., 143., 144., 145., 144., 145., 146.,\n",
       "        143., 146., 151., 156., 155., 154., 153., 148., 143., 142., 143.,\n",
       "        141., 140., 139., 144., 138., 137.],\n",
       "       [141., 143., 143., 140., 145., 142., 137., 132., 149., 143., 140.,\n",
       "        141., 140., 140., 150., 145., 139., 134., 131., 131., 136., 136.,\n",
       "        144., 143., 142., 131., 140., 141.],\n",
       "       [ 83.,  92.,  94.,  79.,  84.,  86.,  89.,  78., 110., 123., 143.,\n",
       "        137., 139., 136., 145., 145., 142., 135., 133., 142., 141., 128.,\n",
       "        113., 129., 127., 107., 118., 101.],\n",
       "       [141., 144., 139., 130., 121., 126., 127., 116., 108.,  87., 132.,\n",
       "        146., 154., 157., 163., 162., 163., 158., 164., 136., 110.,  95.,\n",
       "         86.,  95.,  95.,  91., 103.,  96.]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_nyoba = np.array(Image.open(image_name).rotate(rotation).resize((28, 28)).convert('L'), np.float32,copy=True)\n",
    "value_nyoba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have understood, what is in our dataset, let us load our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_nyoba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = 'candi/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the splitting details in the /data/omniglot/splits/train.txt file which has the language name, character number, rotation information and images in /data/omniglot/data/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_split_path = os.path.join(root_dir, 'splits', 'train_2.txt')\n",
    "\n",
    "with open(train_split_path, 'r') as train_split:\n",
    "    train_classes = [line.rstrip() for line in train_split.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of classes\n",
    "no_of_classes = len(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['budha/candi_banyunibo_yogyakarta_budha/rot000',\n",
       " 'budha/candi_banyunibo_yogyakarta_budha/rot090',\n",
       " 'budha/candi_banyunibo_yogyakarta_budha/rot180',\n",
       " 'budha/candi_banyunibo_yogyakarta_budha/rot270',\n",
       " 'budha/candi_borobudur_magelang_budha/rot000',\n",
       " 'budha/candi_borobudur_magelang_budha/rot090',\n",
       " 'budha/candi_borobudur_magelang_budha/rot180',\n",
       " 'budha/candi_borobudur_magelang_budha/rot270',\n",
       " 'budha/candi_brahu_mojokerto_budha/rot000',\n",
       " 'budha/candi_brahu_mojokerto_budha/rot090',\n",
       " 'budha/candi_brahu_mojokerto_budha/rot180',\n",
       " 'budha/candi_brahu_mojokerto_budha/rot270',\n",
       " 'budha/candi_jago_malang_budha/rot000',\n",
       " 'budha/candi_jago_malang_budha/rot090',\n",
       " 'budha/candi_jago_malang_budha/rot180',\n",
       " 'budha/candi_jago_malang_budha/rot270',\n",
       " 'budha/candi_kalasan_yogyakarta_budha/rot000',\n",
       " 'budha/candi_kalasan_yogyakarta_budha/rot090',\n",
       " 'budha/candi_kalasan_yogyakarta_budha/rot180',\n",
       " 'budha/candi_kalasan_yogyakarta_budha/rot270',\n",
       " 'budha/candi_lumbung_magelang_budha/rot000',\n",
       " 'budha/candi_lumbung_magelang_budha/rot090',\n",
       " 'budha/candi_lumbung_magelang_budha/rot180',\n",
       " 'budha/candi_lumbung_magelang_budha/rot270',\n",
       " 'budha/candi_mendut_magelang_budha/rot000',\n",
       " 'budha/candi_mendut_magelang_budha/rot090',\n",
       " 'budha/candi_mendut_magelang_budha/rot180',\n",
       " 'budha/candi_mendut_magelang_budha/rot270',\n",
       " 'budha/candi_muara_takus_riau_budha/rot000',\n",
       " 'budha/candi_muara_takus_riau_budha/rot090',\n",
       " 'budha/candi_muara_takus_riau_budha/rot180',\n",
       " 'budha/candi_muara_takus_riau_budha/rot270',\n",
       " 'budha/candi_ngawen_magelang_budha/rot000',\n",
       " 'budha/candi_ngawen_magelang_budha/rot090',\n",
       " 'budha/candi_ngawen_magelang_budha/rot180',\n",
       " 'budha/candi_ngawen_magelang_budha/rot270',\n",
       " 'budha/candi_pawon_magelang_budha/rot000',\n",
       " 'budha/candi_pawon_magelang_budha/rot090',\n",
       " 'budha/candi_pawon_magelang_budha/rot180',\n",
       " 'budha/candi_pawon_magelang_budha/rot270',\n",
       " 'budha/candi_penampihan_tulungagung_hindu/rot000',\n",
       " 'budha/candi_penampihan_tulungagung_hindu/rot090',\n",
       " 'budha/candi_penampihan_tulungagung_hindu/rot180',\n",
       " 'hindu/candi_penampihan_tulungagung_hindu/rot270',\n",
       " 'hindu/candi_arjuna_banjarnegara_hindu/rot000',\n",
       " 'hindu/candi_arjuna_banjarnegara_hindu/rot090',\n",
       " 'hindu/candi_arjuna_banjarnegara_hindu/rot180',\n",
       " 'hindu/candi_arjuna_banjarnegara_hindu/rot270',\n",
       " 'hindu/candi_cetho_garut_hindu/rot000',\n",
       " 'hindu/candi_cetho_garut_hindu/rot090',\n",
       " 'hindu/candi_cetho_garut_hindu/rot180',\n",
       " 'hindu/candi_cetho_garut_hindu/rot270',\n",
       " 'hindu/candi_gatotkaca_banjarnegara_hindu/rot000',\n",
       " 'hindu/candi_gatotkaca_banjarnegara_hindu/rot090',\n",
       " 'hindu/candi_gatotkaca_banjarnegara_hindu/rot180',\n",
       " 'hindu/candi_gatotkaca_banjarnegara_hindu/rot270',\n",
       " 'hindu/candi_gebang_yogyakarta_hindu/rot000',\n",
       " 'hindu/candi_gebang_yogyakarta_hindu/rot090',\n",
       " 'hindu/candi_gebang_yogyakarta_hindu/rot180',\n",
       " 'hindu/candi_gebang_yogyakarta_hindu/rot270',\n",
       " 'hindu/candi_ijo_yogyakarta_hindu/rot000',\n",
       " 'hindu/candi_ijo_yogyakarta_hindu/rot090',\n",
       " 'hindu/candi_ijo_yogyakarta_hindu/rot180',\n",
       " 'hindu/candi_ijo_yogyakarta_hindu/rot270',\n",
       " 'hindu/candi_kalicilik_blitar_hindu/rot000',\n",
       " 'hindu/candi_kalicilik_blitar_hindu/rot090',\n",
       " 'hindu/candi_kalicilik_blitar_hindu/rot180',\n",
       " 'hindu/candi_kalicilik_blitar_hindu/rot270',\n",
       " 'hindu/candi_kethek_karanganyar_hindu/rot000',\n",
       " 'hindu/candi_kethek_karanganyar_hindu/rot090',\n",
       " 'hindu/candi_kethek_karanganyar_hindu/rot180',\n",
       " 'hindu/candi_kethek_karanganyar_hindu/rot270',\n",
       " 'hindu/candi_kidal_malang_hindu/rot000',\n",
       " 'hindu/candi_kidal_malang_hindu/rot090',\n",
       " 'hindu/candi_kidal_malang_hindu/rot180',\n",
       " 'hindu/candi_kidal_malang_hindu/rot270',\n",
       " 'hindu/candi_ngetos_nganjuk_hindu/rot000',\n",
       " 'hindu/candi_ngetos_nganjuk_hindu/rot090',\n",
       " 'hindu/candi_ngetos_nganjuk_hindu/rot180',\n",
       " 'hindu/candi_ngetos_nganjuk_hindu/rot270',\n",
       " 'hindu/candi_pari_sidoarjo_hindu/rot000',\n",
       " 'hindu/candi_pari_sidoarjo_hindu/rot090',\n",
       " 'hindu/candi_pari_sidoarjo_hindu/rot180',\n",
       " 'hindu/candi_pari_sidoarjo_hindu/rot270',\n",
       " 'hindu/candi_pringapus_temanggung_hindu/rot000',\n",
       " 'hindu/candi_pringapus_temanggung_hindu/rot090',\n",
       " 'hindu/candi_pringapus_temanggung_hindu/rot180',\n",
       " 'hindu/candi_pringapus_temanggung_hindu/rot270',\n",
       " 'hindu/candi_angin_jepara_hindu/rot000',\n",
       " 'hindu/candi_angin_jepara_hindu/rot090',\n",
       " 'hindu/candi_angin_jepara_hindu/rot180',\n",
       " 'hindu/candi_angin_jepara_hindu/rot270',\n",
       " 'hindu/candi_dadi_2_tulungagung_hindu/rot000',\n",
       " 'hindu/candi_dadi_2_tulungagung_hindu/rot090',\n",
       " 'hindu/candi_dadi_2_tulungagung_hindu/rot180',\n",
       " 'hindu/candi_dadi_2_tulungagung_hindu/rot270',\n",
       " 'hindu/candi_gunung_kawi_bali_hindu/rot000',\n",
       " 'hindu/candi_gunung_kawi_bali_hindu/rot090',\n",
       " 'hindu/candi_gunung_kawi_bali_hindu/rot180',\n",
       " 'hindu/candi_gunung_kawi_bali_hindu/rot270',\n",
       " 'hindu/candi_sukuh_karanganyar_hindu/rot000',\n",
       " 'hindu/candi_sukuh_karanganyar_hindu/rot090',\n",
       " 'hindu/candi_sukuh_karanganyar_hindu/rot180',\n",
       " 'hindu/candi_sukuh_karanganyar_hindu/rot270']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the number of examples to 20, as we have 20 example per class in our dataset, and also we set image width and height to 28 x 28:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of examples\n",
    "num_examples = 20\n",
    "\n",
    "#image width\n",
    "img_width = 28\n",
    "\n",
    "#image height\n",
    "img_height = 28\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize our training dataset with a shape as a number of classes, number of examples, image height and image width:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = np.zeros([no_of_classes, num_examples, img_height, img_width], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 20, 28, 28)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we read all the images, convert it to numpy array and store it our train_dataset array with their label and values, that is,  train_dataset = [label, values]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for label, name in enumerate(train_classes):\n",
    "    alphabet, character, rotation = name.split('/')\n",
    "    rotation = float(rotation[4:])\n",
    "    img_dir = os.path.join(root_dir, alphabet, character)\n",
    "    img_files = glob.glob(os.path.join(img_dir, '*.PNG'))\n",
    "    # print(img_dir)\n",
    "  \n",
    "    \n",
    "    for index, img_file in enumerate(img_files):\n",
    "        values = np.array(Image.open(img_file).rotate(rotation).resize((img_width, img_height)).convert('L'), np.float32, copy=False)\n",
    "        train_dataset[label, index] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label,name in enumerate(train_classes):\n",
    "\n",
    "#     alphabet, rotation = name.split('/')\n",
    "#     rotation = float(rotation[3:])\n",
    "#     img_dir = os.path.join(root_dir, alphabet)\n",
    "#     img_files = glob.glob(os.path.join(img_dir, '*.PNG'))\n",
    "\n",
    "#     for index, img_file in enumerate(img_files):\n",
    "#         values = 1. - np.array(Image.open(img_file).rotate(rotation).resize((img_width, img_height)), np.float32, copy=False)\n",
    "#         # print(index)\n",
    "#         train_dataset[label, index] = values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 20, 28, 28)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[183., 201., 223., ..., 224., 221., 216.],\n",
       "         [196., 177., 211., ..., 210., 204., 199.],\n",
       "         [229., 207., 225., ..., 190., 185., 184.],\n",
       "         ...,\n",
       "         [ 88., 127., 114., ..., 103.,  47.,  16.],\n",
       "         [ 58.,  77.,  61., ..., 112.,  86.,  76.],\n",
       "         [ 61.,  75.,  97., ..., 121., 109.,  88.]],\n",
       "\n",
       "        [[112., 107., 109., ...,  99.,  95.,  94.],\n",
       "         [106., 104., 104., ...,  93.,  93.,  94.],\n",
       "         [ 99.,  97., 100., ...,  85.,  89.,  91.],\n",
       "         ...,\n",
       "         [ 52.,  50.,  61., ..., 101.,  89.,  83.],\n",
       "         [ 87.,  91.,  93., ...,  99.,  97.,  92.],\n",
       "         [127., 126., 127., ..., 126., 125., 126.]],\n",
       "\n",
       "        [[232., 236., 236., ..., 223., 231., 234.],\n",
       "         [226., 228., 230., ..., 223., 227., 229.],\n",
       "         [220., 221., 227., ..., 218., 219., 221.],\n",
       "         ...,\n",
       "         [100., 121., 129., ...,  73.,  79., 110.],\n",
       "         [ 90.,  80.,  85., ...,  64.,  78., 112.],\n",
       "         [ 93.,  91.,  68., ...,  65.,  81., 101.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "       [[[216., 199., 184., ...,  16.,  76.,  88.],\n",
       "         [221., 204., 185., ...,  47.,  86., 110.],\n",
       "         [225., 210., 190., ..., 103., 112., 121.],\n",
       "         ...,\n",
       "         [223., 211., 225., ..., 114.,  61.,  98.],\n",
       "         [201., 177., 207., ..., 127.,  77.,  74.],\n",
       "         [183., 196., 228., ...,  87.,  58.,  61.]],\n",
       "\n",
       "        [[ 94.,  93.,  91., ...,  82.,  92., 126.],\n",
       "         [ 95.,  93.,  89., ...,  89.,  97., 125.],\n",
       "         [ 99.,  93.,  85., ..., 101.,  99., 125.],\n",
       "         ...,\n",
       "         [109., 104., 100., ...,  61.,  93., 127.],\n",
       "         [107., 105.,  97., ...,  50.,  91., 126.],\n",
       "         [112., 106., 100., ...,  52.,  87., 127.]],\n",
       "\n",
       "        [[234., 228., 221., ..., 110., 112., 102.],\n",
       "         [231., 227., 219., ...,  79.,  78.,  81.],\n",
       "         [223., 223., 218., ...,  73.,  64.,  65.],\n",
       "         ...,\n",
       "         [235., 230., 227., ..., 129.,  85.,  68.],\n",
       "         [237., 228., 221., ..., 121.,  79.,  91.],\n",
       "         [232., 226., 220., ..., 100.,  90.,  93.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "       [[[  0.,   5., 179., ...,   0.,   0.,   0.],\n",
       "         [  0.,  20., 214., ...,  23.,  10.,   0.],\n",
       "         [  0.,  47., 224., ..., 107.,  67.,  12.],\n",
       "         ...,\n",
       "         [188., 222., 220., ..., 101.,  16.,   0.],\n",
       "         [  1.,  22.,  43., ..., 114.,  11.,   0.],\n",
       "         [  0.,   0.,   0., ...,  89.,   3.,   0.]],\n",
       "\n",
       "        [[  0.,   2.,  80., ...,   0.,   0.,   0.],\n",
       "         [  0.,  10.,  97., ...,  28.,  12.,   1.],\n",
       "         [  0.,  22., 101., ..., 123., 121.,  70.],\n",
       "         ...,\n",
       "         [ 80.,  98., 107., ..., 112.,  27.,   0.],\n",
       "         [  1.,  10.,  23., ..., 115.,  12.,   0.],\n",
       "         [  0.,   0.,   0., ..., 105.,   3.,   0.]],\n",
       "\n",
       "        [[  0.,   4., 174., ...,   0.,   0.,   0.],\n",
       "         [  0.,  19., 203., ...,  34.,  18.,   3.],\n",
       "         [  0.,  43., 215., ..., 112., 136.,  86.],\n",
       "         ...,\n",
       "         [174., 206., 218., ..., 141.,  33.,   0.],\n",
       "         [  1.,  21.,  45., ..., 124.,  15.,   0.],\n",
       "         [  0.,   0.,   0., ...,  52.,   1.,   0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "       [[[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,  14.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   6.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   1.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   1., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,  10., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,  21., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,  20.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,  11.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   2.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,  14., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,  20., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "       [[[  0.,   0.,   0., ...,  16.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   3.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   4., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,  10., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ..., 111.,  90.,  20.],\n",
       "         [  0.,   0.,   0., ..., 108.,  80.,   6.],\n",
       "         [  0.,   0.,   0., ..., 108.,  70.,   0.],\n",
       "         ...,\n",
       "         [  0., 130., 209., ...,   0.,   0.,   0.],\n",
       "         [ 15., 161., 159., ...,   0.,   0.,   0.],\n",
       "         [ 48., 140.,  87., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ..., 171., 167.,  41.],\n",
       "         [  0.,   0.,   0., ..., 172., 151.,  12.],\n",
       "         [  0.,   0.,   0., ..., 174., 122.,   0.],\n",
       "         ...,\n",
       "         [  0., 141., 181., ...,   0.,   0.,   0.],\n",
       "         [ 15., 194., 150., ...,   0.,   0.,   0.],\n",
       "         [ 56., 215., 138., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,   0.,   0.,   0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded our training data, we need to create embeddings for them. We generate the embeddings using a convolution operation as our inputs are images. So, we define a convolutional block with 64 filters with batch normalization and ReLU as the activation function. Followed by we perform max pooling operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def convolution_block(inputs, out_channels, name='conv'):\n",
    "\n",
    "    conv = tf.keras.layers.Conv2D(out_channels, kernel_size=3, padding='same')(inputs)\n",
    "    conv = tf.keras.layers.BatchNormalization(momentum=0.99, scale=True, center=True)(conv)\n",
    "    conv = tf.keras.layers.Activation('relu')(conv)\n",
    "    conv = tf.keras.layers.MaxPooling2D(pool_size=2)(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define our embedding function which gives us the embedding comprising of four convolutional blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_embeddings(support_set, h_dim, z_dim, reuse=False):\n",
    "\n",
    "        net = convolution_block(support_set, h_dim)\n",
    "        net = convolution_block(net, h_dim)\n",
    "        net = convolution_block(net, h_dim) \n",
    "        net = convolution_block(net, z_dim) \n",
    "        flatten_layer = tf.keras.layers.Flatten()\n",
    "        net = flatten_layer(net)\n",
    "        \n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we don't use our whole dataset for training, since we are one shot learning, we sample some data points from each class as a support set and train the network using the support set in an episodic fashion. \n",
    "\n",
    "\n",
    "Now we define some of the important variables, we consider a 60-way 5-shot learning scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of classes\n",
    "num_way = 2\n",
    "\n",
    "#number of examples per class for support set\n",
    "num_shot = 5  \n",
    "\n",
    "#number of query points\n",
    "num_query = 5 \n",
    "\n",
    "#number of examples\n",
    "num_examples = 20\n",
    "\n",
    "h_dim = 64\n",
    "\n",
    "z_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize placeholders for our support set and query set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "support_set = tf.compat.v1.placeholder(tf.float32, [None, None, img_height, img_width, channels])\n",
    "query_set = tf.compat.v1.placeholder(tf.float32, [None, None, img_height, img_width, channels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we store the shape of our support set and query set in support_set_shape and query_set_shape respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "support_set_shape = tf.shape(support_set)\n",
    "query_set_shape = tf.shape(query_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of classes and number of data points in the support set and number of data points in the query set for initializing our support and query sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes, num_support_points = support_set_shape[0], support_set_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_query_points = query_set_shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the placeholder for our label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int64, [None, None])\n",
    "\n",
    "#convert the label to one hot\n",
    "y_one_hot = tf.one_hot(y, depth=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we generate the embeddings for our support set using our embedding function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "support_set_embeddings = get_embeddings(tf.reshape(support_set, [num_classes * num_support_points, img_height, img_width, channels]), h_dim, z_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the prototype of each class which is the mean vector of the support set embeddings of the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dimension = tf.shape(support_set_embeddings)[-1]\n",
    "\n",
    "class_prototype = tf.reduce_mean(tf.reshape(support_set_embeddings, [num_classes, num_support_points, embedding_dimension]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use our same embedding function for getting embeddings of the query set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_set_embeddings = get_embeddings(tf.reshape(query_set, [num_classes * num_query_points, img_height, img_width, channels]), h_dim, z_dim, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that, we have the class prototype and query set embeddings, we define a distance function which gives us the distance between the class prototypes and query set embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "\n",
    "    N, D = tf.shape(a)[0], tf.shape(a)[1]\n",
    "    M = tf.shape(b)[0]\n",
    "    a = tf.tile(tf.expand_dims(a, axis=1), (1, M, 1))\n",
    "    b = tf.tile(tf.expand_dims(b, axis=0), (N, 1, 1))\n",
    "    return tf.reduce_mean(tf.square(a - b), axis=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the distance between the class prototype and query set embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance = euclidean_distance(class_prototype,query_set_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get the probability for each class as a softmax to the distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_probability = tf.reshape(tf.nn.log_softmax(-distance), [num_classes, num_query_points, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = -tf.reduce_mean(tf.reshape(tf.reduce_sum(tf.multiply(y_one_hot, predicted_probability), axis=-1), [-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.to_float(tf.equal(tf.argmax(predicted_probability, axis=-1), y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Adam optimizer for minimizing the loss:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we start our tensorflow session and train the model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Episode 10 : Loss: 4.409198760986328, Accuracy: 0.5\n",
      "Epoch 1 : Episode 20 : Loss: 2.3422904014587402, Accuracy: 0.5\n",
      "Epoch 1 : Episode 30 : Loss: 2.305872678756714, Accuracy: 0.5\n",
      "Epoch 1 : Episode 40 : Loss: 2.3034584522247314, Accuracy: 0.5\n",
      "Epoch 1 : Episode 50 : Loss: 2.3013694286346436, Accuracy: 0.5\n",
      "Epoch 1 : Episode 60 : Loss: 2.301924228668213, Accuracy: 0.5\n",
      "Epoch 1 : Episode 70 : Loss: 2.303318500518799, Accuracy: 0.5\n",
      "Epoch 1 : Episode 80 : Loss: 2.311032772064209, Accuracy: 0.5\n",
      "Epoch 1 : Episode 90 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 1 : Episode 100 : Loss: 2.3015854358673096, Accuracy: 0.5\n",
      "Epoch 2 : Episode 10 : Loss: 2.3030848503112793, Accuracy: 0.5\n",
      "Epoch 2 : Episode 20 : Loss: 2.3025081157684326, Accuracy: 0.5\n",
      "Epoch 2 : Episode 30 : Loss: 2.3029913902282715, Accuracy: 0.5\n",
      "Epoch 2 : Episode 40 : Loss: 2.30238676071167, Accuracy: 0.5\n",
      "Epoch 2 : Episode 50 : Loss: 2.3024327754974365, Accuracy: 0.6000000238418579\n",
      "Epoch 2 : Episode 60 : Loss: 2.302691698074341, Accuracy: 0.6000000238418579\n",
      "Epoch 2 : Episode 70 : Loss: 2.303238868713379, Accuracy: 0.5\n",
      "Epoch 2 : Episode 80 : Loss: 2.3037447929382324, Accuracy: 0.5\n",
      "Epoch 2 : Episode 90 : Loss: 2.3025918006896973, Accuracy: 0.4000000059604645\n",
      "Epoch 2 : Episode 100 : Loss: 2.3026576042175293, Accuracy: 0.5\n",
      "Epoch 3 : Episode 10 : Loss: 2.302608013153076, Accuracy: 0.5\n",
      "Epoch 3 : Episode 20 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 3 : Episode 30 : Loss: 2.3027307987213135, Accuracy: 0.5\n",
      "Epoch 3 : Episode 40 : Loss: 2.3025784492492676, Accuracy: 0.5\n",
      "Epoch 3 : Episode 50 : Loss: 2.302588939666748, Accuracy: 0.5\n",
      "Epoch 3 : Episode 60 : Loss: 2.3027844429016113, Accuracy: 0.5\n",
      "Epoch 3 : Episode 70 : Loss: 2.3026459217071533, Accuracy: 0.5\n",
      "Epoch 3 : Episode 80 : Loss: 2.3026294708251953, Accuracy: 0.5\n",
      "Epoch 3 : Episode 90 : Loss: 2.3025403022766113, Accuracy: 0.5\n",
      "Epoch 3 : Episode 100 : Loss: 2.302605152130127, Accuracy: 0.5\n",
      "Epoch 4 : Episode 10 : Loss: 2.302422285079956, Accuracy: 0.5\n",
      "Epoch 4 : Episode 20 : Loss: 2.3026623725891113, Accuracy: 0.5\n",
      "Epoch 4 : Episode 30 : Loss: 2.302584409713745, Accuracy: 0.5\n",
      "Epoch 4 : Episode 40 : Loss: 2.302581310272217, Accuracy: 0.5\n",
      "Epoch 4 : Episode 50 : Loss: 2.302243709564209, Accuracy: 0.6000000238418579\n",
      "Epoch 4 : Episode 60 : Loss: 2.3026082515716553, Accuracy: 0.5\n",
      "Epoch 4 : Episode 70 : Loss: 2.3025870323181152, Accuracy: 0.5\n",
      "Epoch 4 : Episode 80 : Loss: 2.3025870323181152, Accuracy: 0.5\n",
      "Epoch 4 : Episode 90 : Loss: 2.302598476409912, Accuracy: 0.4000000059604645\n",
      "Epoch 4 : Episode 100 : Loss: 2.302577495574951, Accuracy: 0.5\n",
      "Epoch 5 : Episode 10 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 5 : Episode 20 : Loss: 2.3026039600372314, Accuracy: 0.5\n",
      "Epoch 5 : Episode 30 : Loss: 2.3025920391082764, Accuracy: 0.4000000059604645\n",
      "Epoch 5 : Episode 40 : Loss: 2.303344964981079, Accuracy: 0.4000000059604645\n",
      "Epoch 5 : Episode 50 : Loss: 2.302588939666748, Accuracy: 0.5\n",
      "Epoch 5 : Episode 60 : Loss: 2.302581310272217, Accuracy: 0.6000000238418579\n",
      "Epoch 5 : Episode 70 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 5 : Episode 80 : Loss: 2.3025946617126465, Accuracy: 0.5\n",
      "Epoch 5 : Episode 90 : Loss: 2.30258846282959, Accuracy: 0.5\n",
      "Epoch 5 : Episode 100 : Loss: 2.30259370803833, Accuracy: 0.5\n",
      "Epoch 6 : Episode 10 : Loss: 2.3025519847869873, Accuracy: 0.5\n",
      "Epoch 6 : Episode 20 : Loss: 2.3025827407836914, Accuracy: 0.5\n",
      "Epoch 6 : Episode 30 : Loss: 2.3026111125946045, Accuracy: 0.5\n",
      "Epoch 6 : Episode 40 : Loss: 2.3025848865509033, Accuracy: 0.5\n",
      "Epoch 6 : Episode 50 : Loss: 2.302769422531128, Accuracy: 0.4000000059604645\n",
      "Epoch 6 : Episode 60 : Loss: 2.3025898933410645, Accuracy: 0.5\n",
      "Epoch 6 : Episode 70 : Loss: 2.3026106357574463, Accuracy: 0.5\n",
      "Epoch 6 : Episode 80 : Loss: 2.3025765419006348, Accuracy: 0.5\n",
      "Epoch 6 : Episode 90 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 6 : Episode 100 : Loss: 2.3025879859924316, Accuracy: 0.5\n",
      "Epoch 7 : Episode 10 : Loss: 2.3025784492492676, Accuracy: 0.5\n",
      "Epoch 7 : Episode 20 : Loss: 2.3025906085968018, Accuracy: 0.5\n",
      "Epoch 7 : Episode 30 : Loss: 2.302583932876587, Accuracy: 0.5\n",
      "Epoch 7 : Episode 40 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 7 : Episode 50 : Loss: 2.3025832176208496, Accuracy: 0.5\n",
      "Epoch 7 : Episode 60 : Loss: 2.3025670051574707, Accuracy: 0.5\n",
      "Epoch 7 : Episode 70 : Loss: 2.3025879859924316, Accuracy: 0.5\n",
      "Epoch 7 : Episode 80 : Loss: 2.3025755882263184, Accuracy: 0.5\n",
      "Epoch 7 : Episode 90 : Loss: 2.3025755882263184, Accuracy: 0.6000000238418579\n",
      "Epoch 7 : Episode 100 : Loss: 2.302578926086426, Accuracy: 0.6000000238418579\n",
      "Epoch 8 : Episode 10 : Loss: 2.302581310272217, Accuracy: 0.5\n",
      "Epoch 8 : Episode 20 : Loss: 2.302582263946533, Accuracy: 0.6000000238418579\n",
      "Epoch 8 : Episode 30 : Loss: 2.3025903701782227, Accuracy: 0.5\n",
      "Epoch 8 : Episode 40 : Loss: 2.3026039600372314, Accuracy: 0.6000000238418579\n",
      "Epoch 8 : Episode 50 : Loss: 2.3025670051574707, Accuracy: 0.5\n",
      "Epoch 8 : Episode 60 : Loss: 2.3025879859924316, Accuracy: 0.4000000059604645\n",
      "Epoch 8 : Episode 70 : Loss: 2.302581548690796, Accuracy: 0.5\n",
      "Epoch 8 : Episode 80 : Loss: 2.302595853805542, Accuracy: 0.5\n",
      "Epoch 8 : Episode 90 : Loss: 2.302583694458008, Accuracy: 0.800000011920929\n",
      "Epoch 8 : Episode 100 : Loss: 2.3025527000427246, Accuracy: 0.5\n",
      "Epoch 9 : Episode 10 : Loss: 2.3026187419891357, Accuracy: 0.5\n",
      "Epoch 9 : Episode 20 : Loss: 2.30253529548645, Accuracy: 0.699999988079071\n",
      "Epoch 9 : Episode 30 : Loss: 2.3025856018066406, Accuracy: 0.5\n",
      "Epoch 9 : Episode 40 : Loss: 2.3025922775268555, Accuracy: 0.6000000238418579\n",
      "Epoch 9 : Episode 50 : Loss: 2.302583694458008, Accuracy: 0.5\n",
      "Epoch 9 : Episode 60 : Loss: 2.302582263946533, Accuracy: 0.6000000238418579\n",
      "Epoch 9 : Episode 70 : Loss: 2.3025898933410645, Accuracy: 0.4000000059604645\n",
      "Epoch 9 : Episode 80 : Loss: 2.3025920391082764, Accuracy: 0.5\n",
      "Epoch 9 : Episode 90 : Loss: 2.3025991916656494, Accuracy: 0.4000000059604645\n",
      "Epoch 9 : Episode 100 : Loss: 2.302582263946533, Accuracy: 0.5\n",
      "Epoch 10 : Episode 10 : Loss: 2.3025906085968018, Accuracy: 0.5\n",
      "Epoch 10 : Episode 20 : Loss: 2.3026347160339355, Accuracy: 0.5\n",
      "Epoch 10 : Episode 30 : Loss: 2.3025929927825928, Accuracy: 0.5\n",
      "Epoch 10 : Episode 40 : Loss: 2.3025856018066406, Accuracy: 0.5\n",
      "Epoch 10 : Episode 50 : Loss: 2.302610158920288, Accuracy: 0.5\n",
      "Epoch 10 : Episode 60 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 10 : Episode 70 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 10 : Episode 80 : Loss: 2.3025851249694824, Accuracy: 0.6000000238418579\n",
      "Epoch 10 : Episode 90 : Loss: 2.3025848865509033, Accuracy: 0.5\n",
      "Epoch 10 : Episode 100 : Loss: 2.302586078643799, Accuracy: 0.5\n",
      "Epoch 11 : Episode 10 : Loss: 2.302569627761841, Accuracy: 0.5\n",
      "Epoch 11 : Episode 20 : Loss: 2.302584648132324, Accuracy: 0.5\n",
      "Epoch 11 : Episode 30 : Loss: 2.3024916648864746, Accuracy: 0.5\n",
      "Epoch 11 : Episode 40 : Loss: 2.3025803565979004, Accuracy: 0.5\n",
      "Epoch 11 : Episode 50 : Loss: 2.3025922775268555, Accuracy: 0.5\n",
      "Epoch 11 : Episode 60 : Loss: 2.3025856018066406, Accuracy: 0.5\n",
      "Epoch 11 : Episode 70 : Loss: 2.302582263946533, Accuracy: 0.5\n",
      "Epoch 11 : Episode 80 : Loss: 2.302586555480957, Accuracy: 0.5\n",
      "Epoch 11 : Episode 90 : Loss: 2.302581548690796, Accuracy: 0.5\n",
      "Epoch 11 : Episode 100 : Loss: 2.3025670051574707, Accuracy: 0.5\n",
      "Epoch 12 : Episode 10 : Loss: 2.3024063110351562, Accuracy: 0.6000000238418579\n",
      "Epoch 12 : Episode 20 : Loss: 2.302591323852539, Accuracy: 0.5\n",
      "Epoch 12 : Episode 30 : Loss: 2.3025736808776855, Accuracy: 0.5\n",
      "Epoch 12 : Episode 40 : Loss: 2.3026442527770996, Accuracy: 0.5\n",
      "Epoch 12 : Episode 50 : Loss: 2.3025901317596436, Accuracy: 0.4000000059604645\n",
      "Epoch 12 : Episode 60 : Loss: 2.3025848865509033, Accuracy: 0.5\n",
      "Epoch 12 : Episode 70 : Loss: 2.3025870323181152, Accuracy: 0.5\n",
      "Epoch 12 : Episode 80 : Loss: 2.3025522232055664, Accuracy: 0.699999988079071\n",
      "Epoch 12 : Episode 90 : Loss: 2.3025870323181152, Accuracy: 0.5\n",
      "Epoch 12 : Episode 100 : Loss: 2.302586078643799, Accuracy: 0.6000000238418579\n",
      "Epoch 13 : Episode 10 : Loss: 2.3028616905212402, Accuracy: 0.4000000059604645\n",
      "Epoch 13 : Episode 20 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 13 : Episode 30 : Loss: 2.3025856018066406, Accuracy: 0.5\n",
      "Epoch 13 : Episode 40 : Loss: 2.3025901317596436, Accuracy: 0.5\n",
      "Epoch 13 : Episode 50 : Loss: 2.3024959564208984, Accuracy: 0.699999988079071\n",
      "Epoch 13 : Episode 60 : Loss: 2.3024744987487793, Accuracy: 0.6000000238418579\n",
      "Epoch 13 : Episode 70 : Loss: 2.302229404449463, Accuracy: 0.30000001192092896\n",
      "Epoch 13 : Episode 80 : Loss: 2.3025786876678467, Accuracy: 0.5\n",
      "Epoch 13 : Episode 90 : Loss: 2.2940211296081543, Accuracy: 0.5\n",
      "Epoch 13 : Episode 100 : Loss: 2.2977664470672607, Accuracy: 0.699999988079071\n",
      "Epoch 14 : Episode 10 : Loss: 2.3028979301452637, Accuracy: 0.5\n",
      "Epoch 14 : Episode 20 : Loss: 2.303314685821533, Accuracy: 0.5\n",
      "Epoch 14 : Episode 30 : Loss: 2.30060076713562, Accuracy: 0.5\n",
      "Epoch 14 : Episode 40 : Loss: 2.355036973953247, Accuracy: 0.6000000238418579\n",
      "Epoch 14 : Episode 50 : Loss: 2.302591323852539, Accuracy: 0.5\n",
      "Epoch 14 : Episode 60 : Loss: 2.3030710220336914, Accuracy: 0.5\n",
      "Epoch 14 : Episode 70 : Loss: 2.302800178527832, Accuracy: 0.5\n",
      "Epoch 14 : Episode 80 : Loss: 2.3025052547454834, Accuracy: 0.5\n",
      "Epoch 14 : Episode 90 : Loss: 2.3025574684143066, Accuracy: 0.5\n",
      "Epoch 14 : Episode 100 : Loss: 2.2992753982543945, Accuracy: 0.699999988079071\n",
      "Epoch 15 : Episode 10 : Loss: 2.302872896194458, Accuracy: 0.6000000238418579\n",
      "Epoch 15 : Episode 20 : Loss: 2.3025758266448975, Accuracy: 0.5\n",
      "Epoch 15 : Episode 30 : Loss: 2.3025875091552734, Accuracy: 0.5\n",
      "Epoch 15 : Episode 40 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 15 : Episode 50 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 15 : Episode 60 : Loss: 2.302631139755249, Accuracy: 0.6000000238418579\n",
      "Epoch 15 : Episode 70 : Loss: 2.3026106357574463, Accuracy: 0.5\n",
      "Epoch 15 : Episode 80 : Loss: 2.3025805950164795, Accuracy: 0.5\n",
      "Epoch 15 : Episode 90 : Loss: 2.3025853633880615, Accuracy: 0.4000000059604645\n",
      "Epoch 15 : Episode 100 : Loss: 2.302581787109375, Accuracy: 0.6000000238418579\n",
      "Epoch 16 : Episode 10 : Loss: 2.3025848865509033, Accuracy: 0.5\n",
      "Epoch 16 : Episode 20 : Loss: 2.3025994300842285, Accuracy: 0.4000000059604645\n",
      "Epoch 16 : Episode 30 : Loss: 2.302574872970581, Accuracy: 0.6000000238418579\n",
      "Epoch 16 : Episode 40 : Loss: 2.3025856018066406, Accuracy: 0.5\n",
      "Epoch 16 : Episode 50 : Loss: 2.3027021884918213, Accuracy: 0.6000000238418579\n",
      "Epoch 16 : Episode 60 : Loss: 2.3068530559539795, Accuracy: 0.5\n",
      "Epoch 16 : Episode 70 : Loss: 2.3025903701782227, Accuracy: 0.5\n",
      "Epoch 16 : Episode 80 : Loss: 2.3025856018066406, Accuracy: 0.5\n",
      "Epoch 16 : Episode 90 : Loss: 2.3025882244110107, Accuracy: 0.5\n",
      "Epoch 16 : Episode 100 : Loss: 2.3025429248809814, Accuracy: 0.6000000238418579\n",
      "Epoch 17 : Episode 10 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 17 : Episode 20 : Loss: 2.302588939666748, Accuracy: 0.5\n",
      "Epoch 17 : Episode 30 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 17 : Episode 40 : Loss: 2.3025810718536377, Accuracy: 0.5\n",
      "Epoch 17 : Episode 50 : Loss: 2.302598237991333, Accuracy: 0.5\n",
      "Epoch 17 : Episode 60 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 17 : Episode 70 : Loss: 2.302544116973877, Accuracy: 0.5\n",
      "Epoch 17 : Episode 80 : Loss: 2.3028528690338135, Accuracy: 0.5\n",
      "Epoch 17 : Episode 90 : Loss: 2.302567958831787, Accuracy: 0.5\n",
      "Epoch 17 : Episode 100 : Loss: 2.302586317062378, Accuracy: 0.5\n",
      "Epoch 18 : Episode 10 : Loss: 2.302462339401245, Accuracy: 0.5\n",
      "Epoch 18 : Episode 20 : Loss: 2.3026671409606934, Accuracy: 0.6000000238418579\n",
      "Epoch 18 : Episode 30 : Loss: 2.3024697303771973, Accuracy: 0.5\n",
      "Epoch 18 : Episode 40 : Loss: 2.3025875091552734, Accuracy: 0.5\n",
      "Epoch 18 : Episode 50 : Loss: 2.302577257156372, Accuracy: 0.5\n",
      "Epoch 18 : Episode 60 : Loss: 2.3024723529815674, Accuracy: 0.5\n",
      "Epoch 18 : Episode 70 : Loss: 2.30259108543396, Accuracy: 0.6000000238418579\n",
      "Epoch 18 : Episode 80 : Loss: 2.3028407096862793, Accuracy: 0.5\n",
      "Epoch 18 : Episode 90 : Loss: 2.3025221824645996, Accuracy: 0.5\n",
      "Epoch 18 : Episode 100 : Loss: 2.302593231201172, Accuracy: 0.5\n",
      "Epoch 19 : Episode 10 : Loss: 2.3025717735290527, Accuracy: 0.5\n",
      "Epoch 19 : Episode 20 : Loss: 2.302635431289673, Accuracy: 0.5\n",
      "Epoch 19 : Episode 30 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 19 : Episode 40 : Loss: 2.30258846282959, Accuracy: 0.5\n",
      "Epoch 19 : Episode 50 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 19 : Episode 60 : Loss: 2.3026134967803955, Accuracy: 0.5\n",
      "Epoch 19 : Episode 70 : Loss: 2.3025996685028076, Accuracy: 0.5\n",
      "Epoch 19 : Episode 80 : Loss: 2.302574634552002, Accuracy: 0.5\n",
      "Epoch 19 : Episode 90 : Loss: 2.3025572299957275, Accuracy: 0.5\n",
      "Epoch 19 : Episode 100 : Loss: 2.302560567855835, Accuracy: 0.5\n",
      "Epoch 20 : Episode 10 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 20 : Episode 20 : Loss: 2.3025853633880615, Accuracy: 0.5\n",
      "Epoch 20 : Episode 30 : Loss: 2.302598476409912, Accuracy: 0.5\n",
      "Epoch 20 : Episode 40 : Loss: 2.3025851249694824, Accuracy: 0.5\n",
      "Epoch 20 : Episode 50 : Loss: 2.3025245666503906, Accuracy: 0.6000000238418579\n",
      "Epoch 20 : Episode 60 : Loss: 2.3024680614471436, Accuracy: 0.699999988079071\n",
      "Epoch 20 : Episode 70 : Loss: 2.3025870323181152, Accuracy: 0.5\n",
      "Epoch 20 : Episode 80 : Loss: 2.3024895191192627, Accuracy: 0.6000000238418579\n",
      "Epoch 20 : Episode 90 : Loss: 2.3025853633880615, Accuracy: 0.5\n",
      "Epoch 20 : Episode 100 : Loss: 2.3025853633880615, Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        \n",
    "        # select 60 classes\n",
    "        episodic_classes = np.random.permutation(no_of_classes)[:num_way]\n",
    "        \n",
    "        support = np.zeros([num_way, num_shot, img_height, img_width], dtype=np.float32)\n",
    "        \n",
    "        query = np.zeros([num_way, num_query, img_height, img_width], dtype=np.float32)\n",
    "        \n",
    "        \n",
    "        for index, class_ in enumerate(episodic_classes):\n",
    "            selected = np.random.permutation(num_examples)[:num_shot + num_query]\n",
    "            support[index] = train_dataset[class_, selected[:num_shot]]\n",
    "            \n",
    "            # 5 querypoints per classs\n",
    "            query[index] = train_dataset[class_, selected[num_shot:]]\n",
    "            \n",
    "        support = np.expand_dims(support, axis=-1)\n",
    "        query = np.expand_dims(query, axis=-1)\n",
    "        labels = np.tile(np.arange(num_way)[:, np.newaxis], (1, num_query)).astype(np.uint8)\n",
    "        _, loss_, accuracy_ = sess.run([train, loss, accuracy], feed_dict={support_set: support, query_set: query, y:labels})\n",
    "        \n",
    "        if (episode+1) % 10 == 0:\n",
    "            print('Epoch {} : Episode {} : Loss: {}, Accuracy: {}'.format(epoch+1, episode+1, loss_, accuracy_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
